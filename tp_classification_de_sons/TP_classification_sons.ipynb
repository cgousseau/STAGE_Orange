{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_classification_sons.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8agx3Z5D1e6M",
        "colab_type": "text"
      },
      "source": [
        "Avant toute chose, aller dans Exécution>Modifier le type d'exécution>Accélérateur matériel>GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWLkGw2y0F2W",
        "colab_type": "text"
      },
      "source": [
        "# 1. Construction d'un spectrogramme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWGkEAr30isN",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Pre Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9mxIyql0mak",
        "colab_type": "text"
      },
      "source": [
        "Le son en question : https://soundcloud.com/cl-ment-gousseau-1/pianoscale (quelques notes de piano)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Q6ZNTT0BMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# téléchargement\n",
        "!pip install scdl \n",
        "!scdl -l https://soundcloud.com/cl-ment-gousseau-1/pianoscale\n",
        "  \n",
        "# conversion en .wav\n",
        "import subprocess\n",
        "command = \"ffmpeg -i piano.mp3 -ab 160k -ac 2 -ar 44100 -vn piano.wav\"\n",
        "subprocess.call(command, shell=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9As235WE38-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transformation du fichier .wav en fichier .npy\n",
        "import numpy as np\n",
        "!pip install soundfile \n",
        "import soundfile as sf\n",
        "!pip install librosa\n",
        "import librosa\n",
        "\n",
        "def get_sound_data(path, sr=16000):\n",
        "    data, fsr = sf.read(path)\n",
        "    data_resample = librosa.resample(data.T, fsr, sr)\n",
        "    if len(data_resample.shape) > 1:\n",
        "        data_resample = np.average(data_resample, axis=0)\n",
        "    return data_resample, sr\n",
        "\n",
        "path='piano.wav'\n",
        "signal, sampling_rate = get_sound_data(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tJpGm3z2cHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print('sampling rate = '+str(sampling_rate)+' Hz')\n",
        "plt.plot(signal)\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('amplitude')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_NW4Fr_5-Vj",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Construction des spectrogrammes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfr0gJ7928QE",
        "colab_type": "text"
      },
      "source": [
        "Calculer les melspectrogrammes avec la librairie librosa : \n",
        "\n",
        "* voir https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html#librosa.feature.melspectrogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G129vL_3MoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "melspec = ... # à completer\n",
        "\n",
        "plt.imshow(melspec)\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItDEbBqW3QXk",
        "colab_type": "text"
      },
      "source": [
        "Utiliser un échelle log pour les amplitudes :\n",
        "* voir https://librosa.github.io/librosa/generated/librosa.core.amplitude_to_db\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMVDJ_vn38iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logmelspec = ... # à completer\n",
        "\n",
        "plt.imshow(logmelspec)\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LCNZL594Jds",
        "colab_type": "text"
      },
      "source": [
        "Renverser l'image pour que les basses fréquences soient en bas de l'image :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nGuo_Xs4Up9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logmelspec = ... # à compléter\n",
        "\n",
        "plt.imshow(logmelspec)\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('frequency')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQYAVIrn6Eob",
        "colab_type": "text"
      },
      "source": [
        "# 2. Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDE95IIU6LOb",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Importation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knv5TxPK6bcU",
        "colab_type": "text"
      },
      "source": [
        "Ce sont des sons de la base de données UrbanSound8K : \n",
        "\n",
        "Il y a 8372 sons de moins de 4 secondes appartenant aux classes :\n",
        "* 0 = air_conditioner\n",
        "* 1 = car_horn\n",
        "* 2 = children_playing\n",
        "* 3 = dog_bark\n",
        "* 4 = drilling (=forage)\n",
        "* 5 = engine_idling\n",
        "* 6 = gun_shot\n",
        "* 7 = jackhammer (=marteau-piqueur)\n",
        "* 8 = siren\n",
        "* 9 = street_music\n",
        "\n",
        "1 son appartient à une et une seule classe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtx-qFIE51Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To load a subset of the dataset\n",
        "!wget  https://zenodo.org/record/3354445/files/fold1.zip\n",
        "!unzip fold1.zip\n",
        "  \n",
        "# To load the full dataset\n",
        "#!wget https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz\n",
        "#!gzip -d < UrbanSound8K.tar.gz | tar xvf -"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRdfwPis9wca",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Calcul des logmel-spectrogrammes\n",
        "\n",
        "Les fichiers audios sont découpés en fenêtres de 1s. Le logmel-spectrogramme est calculé pour chaque fenêtre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXpJcZLa9p9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def windows(data, window_size):\n",
        "    start = 0\n",
        "    while start < len(data):\n",
        "        yield int(start), int(start + window_size)\n",
        "        start += window_size \n",
        "        \n",
        "def compute_logmelspec(file_names, bands=64, hop_length=161, n_fft=1024):\n",
        "    \n",
        "    window_size = 16000  \n",
        "    log_specgrams_full = []\n",
        "    log_specgrams_hp = []\n",
        "    class_labels = []\n",
        "    \n",
        "    progress=float(0)\n",
        "    nfiles=len(file_names)\n",
        "    \n",
        "    # for each audio sample\n",
        "    for fn in file_names:\n",
        "        \n",
        "        if np.mod(progress,50)==0:\n",
        "          print(str(np.round(100*progress/nfiles))+str('% completed'))\n",
        "        progress=progress+1\n",
        "        \n",
        "        file_name = fn.split('\\\\')[-1]\n",
        "           \n",
        "        class_label = file_name.split('-')[1]\n",
        "        sound_data, sr = get_sound_data(fn, sr=16000)\n",
        "\n",
        "        # for each audio signal sub-sample window of data\n",
        "        for (start,end) in windows(sound_data, window_size):\n",
        "            if(len(sound_data[start:end]) == window_size):\n",
        "                signal = sound_data[start:end]\n",
        "                # get the log-scaled mel-spectrogram\n",
        "                melspec_full = librosa.feature.melspectrogram(signal, n_mels = bands, hop_length=hop_length, n_fft=n_fft)\n",
        "                logspec_full = librosa.amplitude_to_db(melspec_full)\n",
        "  \n",
        "                #print(logspec_full.shape)\n",
        "\n",
        "                log_specgrams_full.append(logspec_full)\n",
        "                class_labels.append(class_label)\n",
        "\n",
        "    log_specgrams_full = np.asarray(log_specgrams_full)\n",
        "    log_specgrams_full = log_specgrams_full.reshape(log_specgrams_full.shape[0],log_specgrams_full.shape[1],log_specgrams_full.shape[2], 1)\n",
        "    log_specgrams_full = np.flip(log_specgrams_full,axis=1)\n",
        "    \n",
        "    return np.array(log_specgrams_full), np.array(class_labels, dtype = np.int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BquY6T6M-aGT",
        "colab_type": "text"
      },
      "source": [
        "Pour que cela prenne moins de temps, on ne réalise cela que sur un sous-ensemble du jeu de données: fold1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRXGKSgj-T56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "\n",
        "#subset\n",
        "files = glob.glob('fold1/*')\n",
        "\n",
        "#full dataset\n",
        "#files = glob.glob('UrbanSound8K/audio//fold1/*')\n",
        "\n",
        "logmelspec, labels = compute_logmelspec(files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSRKxHSE_A2a",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Visualisation de quelques spectrogrammes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGvPuY9q_Fwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_map = {'0' : 'air_conditioner', '1' : 'car_horn', '2' : 'children_playing', '3' : 'dog_bark', '4' : 'drilling', \n",
        "             '5' : 'engine_idling', '6' : 'gun_shot', '7' : 'jackhammer', '8' : 'siren', '9' : 'street_music'}\n",
        "\n",
        "categories = list(set(labels))\n",
        "sample_idxs = [np.where(labels == label_id)[0][:5] for label_id in categories]\n",
        "\n",
        "plt.figure(figsize=(24, 10))\n",
        "for i in range(10):\n",
        "  for j in range(5):\n",
        "    plt.subplot(5,10,1+i+10*j)\n",
        "    plt.imshow(logmelspec[sample_idxs[i][j],:,:,0], cmap='viridis')\n",
        "    plt.title(class_map[str(i)])\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQyM9uuE_Wub",
        "colab_type": "text"
      },
      "source": [
        "## 2.4. Création d'un réseaux de neurones (de type VGGish)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAAkhELS_k97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.models import Model\n",
        "\n",
        "def create_model():\n",
        "  \n",
        "    input_shape = (64,100,1)\n",
        "\n",
        "    img_input = Input(shape=input_shape)\n",
        "    \n",
        "    x = BatchNormalization()(img_input)\n",
        "\t\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
        "  \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(10, activation='softmax', name='fc2')(x)\n",
        "\n",
        "    model = Model(img_input, x, name='model')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqVHM9ee_yB3",
        "colab_type": "text"
      },
      "source": [
        "## 2.5. One-hot encoding + Création d'une jeu d'entraînement, validation, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCjuxT-__-aQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding\n",
        "from keras.utils import to_categorical\n",
        "y=to_categorical(labels)\n",
        "\n",
        "# Test: 10% des données; Train: 80% des 90% restants; Validation: 20% des 90% restants\n",
        "from sklearn.model_selection import train_test_split\n",
        "xtrainval, xtest, ytrainval, ytest = train_test_split(logmelspec, y, test_size=0.1)\n",
        "xtrain, xval, ytrain, yval = train_test_split(xtrainval, ytrainval, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlLfZuwqi1qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRGzSIqTAp7Y",
        "colab_type": "text"
      },
      "source": [
        "## 2.6. Entraînement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js7ogQobAs93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=create_model()\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
        "history = model.fit(xtrain,ytrain,validation_data=(xval,yval),batch_size=32,epochs=50,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjiN01jA9Tx",
        "colab_type": "text"
      },
      "source": [
        "## 2.7. Visualisation des courbes d'apprentissage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRNNT-zjBC3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "t = f.suptitle('Deep Neural Net Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.2)\n",
        "\n",
        "epochs = list(range(1,51))\n",
        "ax1.plot(history.history['acc'], label='Train Accuracy')\n",
        "ax1.plot(history.history['val_acc'], label='Validation Accuracy')\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "ax1.grid(True)\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(history.history['loss'], label='Train Loss')\n",
        "ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "ax2.grid(True)\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zx_aJAoBFlt",
        "colab_type": "text"
      },
      "source": [
        "## 2.8. Résultats et matrices de confusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRs1k_twBEVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_,acc = model.evaluate(xtest,ytest)\n",
        "print('accuracy = '+str(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm3l02zIBR1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=model.predict(xtest)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels=['air_conditioner','car_horn','children_playing','dog_bark','drilling','engine_idling','gun_shot','jackhammer','siren','street_music']\n",
        "\n",
        "m=confusion_matrix(ytest.argmax(axis=1), predictions.argmax(axis=1))\n",
        "cm=m/np.sum(m,axis=0)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "im = ax.imshow(cm)\n",
        "ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "ax.set(xticks=np.arange(cm.shape[1]),yticks=np.arange(cm.shape[0]),xticklabels=labels, yticklabels=labels,title='normalized confusion matrix',ylabel='True label',xlabel='Predicted label')\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E77CUlc2COaY",
        "colab_type": "text"
      },
      "source": [
        "## 2.9. Merci"
      ]
    }
  ]
}